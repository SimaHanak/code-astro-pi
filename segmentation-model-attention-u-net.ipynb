{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Importing libraries**","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow_io==0.25.0","metadata":{"execution":{"iopub.status.busy":"2023-06-23T08:48:29.052402Z","iopub.execute_input":"2023-06-23T08:48:29.052760Z","iopub.status.idle":"2023-06-23T08:48:45.385296Z","shell.execute_reply.started":"2023-06-23T08:48:29.052731Z","shell.execute_reply":"2023-06-23T08:48:45.384073Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow_io==0.25.0\n  Downloading tensorflow_io-0.25.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting tensorflow-io-gcs-filesystem==0.25.0 (from tensorflow_io==0.25.0)\n  Downloading tensorflow_io_gcs_filesystem-0.25.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow_io\n  Attempting uninstall: tensorflow-io-gcs-filesystem\n    Found existing installation: tensorflow-io-gcs-filesystem 0.31.0\n    Uninstalling tensorflow-io-gcs-filesystem-0.31.0:\n      Successfully uninstalled tensorflow-io-gcs-filesystem-0.31.0\n  Attempting uninstall: tensorflow_io\n    Found existing installation: tensorflow-io 0.31.0\n    Uninstalling tensorflow-io-0.31.0:\n      Successfully uninstalled tensorflow-io-0.31.0\nSuccessfully installed tensorflow-io-gcs-filesystem-0.25.0 tensorflow_io-0.25.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.models import Model\nimport os\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom random import shuffle\nimport tensorflow.keras.backend as K","metadata":{"execution":{"iopub.status.busy":"2023-06-23T08:48:45.387668Z","iopub.execute_input":"2023-06-23T08:48:45.388030Z","iopub.status.idle":"2023-06-23T08:48:55.209731Z","shell.execute_reply.started":"2023-06-23T08:48:45.387994Z","shell.execute_reply":"2023-06-23T08:48:55.208772Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip freeze > requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-06-23T08:48:55.210953Z","iopub.execute_input":"2023-06-23T08:48:55.211710Z","iopub.status.idle":"2023-06-23T08:48:57.841400Z","shell.execute_reply.started":"2023-06-23T08:48:55.211675Z","shell.execute_reply":"2023-06-23T08:48:57.840184Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **Loading data**","metadata":{}},{"cell_type":"code","source":"class DataGeneratorSegmentation(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, names, batch_size=32, dim=(32,32), n_channels=1,\n                 shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.names = names\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.names) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes_batch = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_names_temp = [self.names[k] for k in indexes_batch]\n        \n        # Generate data\n        X, Y, W = self.__data_generation(list_names_temp)\n\n        return X, Y, W\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.names))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_names_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, 3))\n        Y = np.empty((self.batch_size, *self.dim, 1))\n        W = np.empty((self.batch_size, *self.dim, 1))\n\n        # Generate data\n        for i, name in enumerate(list_names_temp):\n            img = cv2.imread(f'/kaggle/input/storms-satellite-imagery/quarter_final/img/{name}')\n            mask = cv2.imread(f'/kaggle/input/storms-satellite-imagery/quarter_final/mask/{name}', 0)\n            img = cv2.resize(img, (self.dim))/255\n            mask = np.reshape(cv2.resize(mask, (self.dim))/255, (*self.dim, 1))\n            weights = np.full((224, 224, 1), 0.2)\n            x_index, y_index, z_index = np.where(mask==1)\n            for x, y, z in zip(x_index, y_index, z_index):\n                weights[x, y, z] = 0.8\n            W[i,] = weights\n            X[i,] = img\n            Y[i,] = mask\n        return X, Y, W","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:27:10.965647Z","iopub.execute_input":"2023-06-15T08:27:10.966449Z","iopub.status.idle":"2023-06-15T08:27:10.983890Z","shell.execute_reply.started":"2023-06-15T08:27:10.966414Z","shell.execute_reply":"2023-06-15T08:27:10.982900Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"list_names = os.listdir('/kaggle/input/storms-satellite-imagery/quarter_final/img/')\nshuffle(list_names)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:27:10.987347Z","iopub.execute_input":"2023-06-15T08:27:10.988193Z","iopub.status.idle":"2023-06-15T08:27:11.432016Z","shell.execute_reply.started":"2023-06-15T08:27:10.988149Z","shell.execute_reply":"2023-06-15T08:27:11.431059Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_list_names = list_names[:-200]\nparams = {'dim': (224, 224), \n          'batch_size': 16, \n          'n_channels': 3, \n          'shuffle': True, \n          'names': train_list_names}\n\ntraining_generator = DataGeneratorSegmentation(**params)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:27:11.433470Z","iopub.execute_input":"2023-06-15T08:27:11.434170Z","iopub.status.idle":"2023-06-15T08:27:11.441533Z","shell.execute_reply.started":"2023-06-15T08:27:11.434130Z","shell.execute_reply":"2023-06-15T08:27:11.440380Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"val_list_names = list_names[-200:]\nparams = {'dim': (224, 224), \n          'batch_size': 16, \n          'n_channels': 3, \n          'shuffle': True, \n          'names': val_list_names}\n\nvalidation_generator = DataGeneratorSegmentation(**params)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:27:11.442880Z","iopub.execute_input":"2023-06-15T08:27:11.443688Z","iopub.status.idle":"2023-06-15T08:27:11.457683Z","shell.execute_reply.started":"2023-06-15T08:27:11.443638Z","shell.execute_reply":"2023-06-15T08:27:11.456678Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# **Building the model**","metadata":{}},{"cell_type":"code","source":"def conv_block(x, num_filters):\n    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = L.BatchNormalization()(x)\n    x = L.Activation(\"relu\")(x)\n \n    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = L.BatchNormalization()(x)\n    x = L.Activation(\"relu\")(x)\n \n    return x","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:27:11.459045Z","iopub.execute_input":"2023-06-15T08:27:11.460284Z","iopub.status.idle":"2023-06-15T08:27:11.471128Z","shell.execute_reply.started":"2023-06-15T08:27:11.460251Z","shell.execute_reply":"2023-06-15T08:27:11.470221Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def encoder_block(x, num_filters):\n    x = conv_block(x, num_filters)\n    p = L.MaxPool2D((2, 2))(x)\n    return x, p","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:27:11.472631Z","iopub.execute_input":"2023-06-15T08:27:11.473077Z","iopub.status.idle":"2023-06-15T08:27:11.482748Z","shell.execute_reply.started":"2023-06-15T08:27:11.473018Z","shell.execute_reply":"2023-06-15T08:27:11.481901Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def attention_gate(g, s, num_filters):\n    Wg = L.Conv2D(num_filters, 1, padding=\"same\")(g)\n    Wg = L.BatchNormalization()(Wg)\n \n    Ws = L.Conv2D(num_filters, 1, padding=\"same\")(s)\n    Ws = L.BatchNormalization()(Ws)\n \n    out = L.Activation(\"relu\")(Wg + Ws)\n    out = L.Conv2D(num_filters, 1, padding=\"same\")(out)\n    out = L.Activation(\"sigmoid\")(out)\n \n    return out * s","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:27:11.484362Z","iopub.execute_input":"2023-06-15T08:27:11.484762Z","iopub.status.idle":"2023-06-15T08:27:11.495837Z","shell.execute_reply.started":"2023-06-15T08:27:11.484729Z","shell.execute_reply":"2023-06-15T08:27:11.494960Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def decoder_block(x, s, num_filters):\n    x = L.UpSampling2D(interpolation=\"bilinear\")(x)\n    s = attention_gate(x, s, num_filters)\n    x = L.Concatenate()([x, s])\n    x = conv_block(x, num_filters)\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:27:11.499610Z","iopub.execute_input":"2023-06-15T08:27:11.500539Z","iopub.status.idle":"2023-06-15T08:27:11.514457Z","shell.execute_reply.started":"2023-06-15T08:27:11.500502Z","shell.execute_reply":"2023-06-15T08:27:11.513629Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def attention_unet(input_shape):\n    \"\"\" Inputs \"\"\"\n    inputs = L.Input(input_shape)\n \n    \"\"\" Encoder \"\"\"\n    s1, p1 = encoder_block(inputs, 64)\n    s2, p2 = encoder_block(p1, 128)\n    s3, p3 = encoder_block(p2, 256)\n    s4, p4 = encoder_block(p3, 512)\n \n    b1 = conv_block(p4, 1024)\n \n    \"\"\" Decoder \"\"\"\n    d1 = decoder_block(b1, s4, 512)\n    d2 = decoder_block(d1, s3, 256)\n    d3 = decoder_block(d2, s2, 128)\n    d4 = decoder_block(d3, s1, 64)\n \n    \"\"\" Outputs \"\"\"\n    outputs = L.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n \n    \"\"\" Model \"\"\"\n    model = Model(inputs, outputs, name=\"Attention-UNET\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:41:22.366977Z","iopub.execute_input":"2023-06-15T08:41:22.367383Z","iopub.status.idle":"2023-06-15T08:41:22.378293Z","shell.execute_reply.started":"2023-06-15T08:41:22.367349Z","shell.execute_reply":"2023-06-15T08:41:22.377310Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model = attention_unet((256, 256, 3))","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:41:22.881254Z","iopub.execute_input":"2023-06-15T08:41:22.881619Z","iopub.status.idle":"2023-06-15T08:41:23.570176Z","shell.execute_reply.started":"2023-06-15T08:41:22.881591Z","shell.execute_reply":"2023-06-15T08:41:23.569193Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# **Training the model**","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras.backend as K\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef tversky(y_true, y_pred, smooth=1, alpha=0.7):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n    return (true_pos + smooth) / (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n\n\ndef tversky_loss(y_true, y_pred):\n    return 1 - tversky(y_true, y_pred)\n\n\ndef focal_tversky_loss(y_true, y_pred, gamma=0.75):\n    tv = tversky(y_true, y_pred)\n    return K.pow((1 - tv), gamma) ","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:42:02.247250Z","iopub.execute_input":"2023-06-15T08:42:02.247831Z","iopub.status.idle":"2023-06-15T08:42:02.260900Z","shell.execute_reply.started":"2023-06-15T08:42:02.247774Z","shell.execute_reply":"2023-06-15T08:42:02.259931Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n              loss=dice_coef_loss, \n              metrics=[dice_coef])","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:42:02.740387Z","iopub.execute_input":"2023-06-15T08:42:02.742055Z","iopub.status.idle":"2023-06-15T08:42:02.761871Z","shell.execute_reply.started":"2023-06-15T08:42:02.742018Z","shell.execute_reply":"2023-06-15T08:42:02.761023Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"history = model.fit(training_generator, \n                    epochs=10,\n                    validation_data=validation_generator)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:42:03.213869Z","iopub.execute_input":"2023-06-15T08:42:03.214871Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n285/285 [==============================] - 334s 941ms/step - loss: 0.1356 - dice_coef: 0.4053 - val_loss: 0.1436 - val_dice_coef: 0.3716\nEpoch 2/10\n285/285 [==============================] - 264s 925ms/step - loss: 0.1300 - dice_coef: 0.4302 - val_loss: 0.1466 - val_dice_coef: 0.3594\nEpoch 3/10\n285/285 [==============================] - 264s 924ms/step - loss: 0.1289 - dice_coef: 0.4329 - val_loss: 0.1313 - val_dice_coef: 0.4286\nEpoch 4/10\n285/285 [==============================] - 264s 924ms/step - loss: 0.1276 - dice_coef: 0.4398 - val_loss: 0.1620 - val_dice_coef: 0.2968\nEpoch 5/10\n285/285 [==============================] - 263s 923ms/step - loss: 0.1295 - dice_coef: 0.4306 - val_loss: 0.1460 - val_dice_coef: 0.3561\nEpoch 6/10\n285/285 [==============================] - 263s 921ms/step - loss: 0.1252 - dice_coef: 0.4508 - val_loss: 0.2341 - val_dice_coef: 6.3008e-05\nEpoch 7/10\n285/285 [==============================] - ETA: 0s - loss: 0.1271 - dice_coef: 0.4425","output_type":"stream"}]},{"cell_type":"code","source":"plt.plot(history.history[\"loss\"], 'b')\nplt.plot(history.history[\"dice_coef\"], 'r')\nplt.plot(history.history[\"val_loss\"], 'b', linestyle='dashed')\nplt.plot(history.history[\"val_dice_coef\"], 'r', linestyle='dashed')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Predict**","metadata":{}},{"cell_type":"code","source":"predict = []\nfor name in os.listdir('/kaggle/input/exam-images/exam_images/'):\n    img = cv2.imread(f'/kaggle/input/exam-images/exam_images/{name}')\n    img = np.reshape(cv2.resize(img, (256, 256))/255, (1, 256, 256, 3))\n    predict.append(model.predict(img, verbose=0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#os.makedirs('/kaggle/working/predictions/')\nfor i, prediction in enumerate(predict):\n    ret, thresh = cv2.threshold(prediction[0]*255, 3, 255, 0)\n    cv2.imwrite(f\"/kaggle/working/predictions/img{i:03d}.jpg\", prediction[0]*255)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import FileLink, display\n\ndef download_file(path, download_file_name):\n    os.chdir('/kaggle/working/')\n    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n    command = f\"zip {zip_name} {path} -r\"\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(\"Unable to run zip command!\")\n        print(result.stderr)\n        return\n    display(FileLink(f'{download_file_name}.zip'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"download_file('/kaggle/working/predictions/', 'out')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}